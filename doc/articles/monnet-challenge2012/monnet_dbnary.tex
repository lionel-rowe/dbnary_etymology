\documentclass[10pt, a4paper]{article}
%\usepackage{lrec2006}
\usepackage{graphicx}

\usepackage[utf8]{inputenc}

\usepackage{alltt}  
\usepackage{tabularx}  
\usepackage{tipa}  
\usepackage{natbib}

\usepackage{color}
\usepackage{relsize}
\usepackage{url}

\newcommand{\mytexttt}[1]{\texttt{\textscale{0.9}{#1}}}

\definecolor{MyGray}{rgb}{0.90,0.90,0.90}
\makeatletter\newenvironment{graybox}{%
   \begin{lrbox}{\@tempboxa}\begin{minipage}{.98\textwidth}}{\end{minipage}\end{lrbox}%
   \colorbox{MyGray}{\usebox{\@tempboxa}}
}\makeatother


\title{Dbnary: Wiktionary as a Lemon Based RDF Multilingual Lexical Ressource}

\author{Gilles SÃ©rasset\\
UJF-Grenoble 1, Laboratoire d'Informatique de Grenoble\\ 
GETALP Team, BP 53, 38051 Grenoble cedex 9, France \\ 
\texttt{gilles.serasset@imag.fr}
\\}

\date{}

\begin{document}

\maketitle

\begin{abstract}
This short paper presents our effort to extract an RDF Multilingual Lexical Resource from the wiktionary data. This lexical resource is structured using the LEMON Model.\\
The extracted data is registered at \url{http://thedatahub.org/dataset/dbnary}.
\textbf{Keywords:} Wiktionary, Multilingual Lexical Resource, Lexical Networks, LEMON, RDF.
\end{abstract}


\section{Introduction}

The GETALP (Study group for speech and language translation/processing) team of the LIG (Laboratoire d'Informatique de Grenoble) is in need for multilingual lexical resources that should include language correspondences (translations) and word sense definitions. In this regard, the set data included in the different wiktionary language edition is a precious mine.

Alas, many inconsistencies, errors, difference in usage do exist in the different wiktionary language edition. Hence, we decided to provide an effort to extract precious data from this source and provide it to the community a Linked Data. After a first version that used an RDF version of the LMF model and described in \cite{serasset:lrec2012}, we decided to adapt our extractors to LEMON model.

\section{Extracting data from wiktionary}

Errors and incoherence are inherent to a contributive resource like wiktionary. Some language editions (like French and English) have many moderators that do limit the number of incoherence among entries of the same language. Moreover, such languages, which contain the most data, use many \textit{templates} that simplify the extraction process. For instance, the translation section of the French dictionary usually uses a template to identify each individual translation.

This is not true anymore with less developed wiktionary language editions. For instance, in the Finnish edition, some translations are introduced by a template giving the language (e.g. \{fr\} precedes French translation) and others are introduced by the string "ranska" which is the Finnish translation for "French". In this case the translator needs to know the Finnish translation of all language names to cope with the second case and avoid losing almost half of the available translation data.

Our extractor is written in java and is open-source (LGPL licensed, available at \url{http://dbnary.forge.imag.fr}).
\section{Extracted Data as a LEMON Lexical Resource}

\subsection{Extracted Entries}

The main goal of our efforts is not to extensively reflect wiktionary data, but to create a lexical resource that is structured as a set of monolingual dictionaries + bilingual translation information. Such data is already useful for several application, but it is merely a starting point for a future multilingual lexical database.

The monolingual data is always extracted from its own wiktionary lexical edition. For instance, the French lexical data is extracted from French language edition (the data available on http://fr.wiktionary.org). Hence, we completely disregard the French data that may be found in other language editions.

We also filtered out some part of speeches in order to produce a result that is closer to existing monolingual dictionaries. For instance, in French, we disregard abstract entries that are prefixes, suffixes or flexions (e.g.: we do not extract data concerning \textit{in-} or \textit{-al} that are prefixes/suffixes and have a dedicated page in French language Edition). 

Our work did focus only on the lexical data. Hence, we do not provide any reference to any ontology.  

\subsection{LEMON and non-LEMON modeled Extracted Data}

All the extracted data could not be structured using LEMON only model. For instance, LEMON does not contain anything to represent translations between languages as it assumes that such a translation will be handled by the ontology description. Moreover, LEMON assumes that all data is well-formed and fully specified. As an example, synonymy relation is a property linking a \textit{Lexical Sense} to another \textit{Lexical Sense}. While this is correct to assume as a \textit{principle}, this does not account for the huge amount of legacy data that is available in dictionaries and lexical databases.

In order to cope with this legacy data, we introduced several classes and properties that are not LEMON entities. However, when a piece of data is representable as a LEMON entity, then it is done so. 

\subsection{Example of an extracted lexical entry}

The dbnary extracted data contains the following information:

\begin{description}
\item[Lexical Entries:] an instance of \texttt{lemon:LexicalEntry} corresponds more or less to a "part of speech" section in a wiktionary page. This means that it is defined by an unique canonical written form, a part of speech and a number (in case of homonymy). When wiktionary data allows for it, we try to distinguish between \texttt{lemon:Word} and \texttt{lemon:Phrase} that are defined as specific lexical entries.
\item[Lexical Forms:] lexical entries are connected, through the \texttt{lemon:canonicalForm} property to a lexical form that gathers a written form and a pronunciation (when available). They may also be connected to alternative spelling through \texttt{lemon:lexicalVariant} property. 
\item[Lexical Senses:] an instance of \texttt{lemon:LexicalSense} correspond to one definition in the wiktionary page. It is the target of the \texttt{lemon:sense} property of its containing Lexical Entry. Each lexical sense is associated with a \texttt{dbpedia:senseNumber} property (that contains the rank at which the definition appeared in the wiktionary page) and a \texttt{lemon:definition} property.
\item[Part Of Speech] part of speech properties are available in the wiktionary data in 2 distinct properties that are attached to lexical entries:
\begin{itemize}
\item \texttt{dbnary:partOfSpeech} is a data property whose value is a string that contains the part of speech \textit{as it was defined in wiktionary} 
\item \texttt{lexinfo:partOfSpeech} is a standard property that is bound to isocat data categories and which value is a correct isocat data category. This property is only available when the mapping between wiktionary part of speech and isocat part of speech is known.
\end{itemize}
\item[Vocable:] the main unit of data in wiktionary is a \textit{wiktionary page} that may contain several lexical entries. Many lexical data is represented as links to a \textit{page}. Most of the time, there is not enough data to know to which lexical entry (or lexical sense) these links point to. Hence if we want to keep these \textit{underspecified} relations, we need to define units that represent wiktionary pages. This is the role of the \texttt{dbnary:Vocable} class. Instances of this class are related to their lexical entries through the \texttt{dbnary:refersTo} property. 
\item[Nyms:] most wiktionary language edition do provide "nym" relations (mainly synonym, antonym, hypernym, hyponym, meronym and holonym). As we already mentioned this legacy data is not representable using LEMON model, unless we know for sure the source and target lexical sense of the relation. In order to cope with this legacy data, 6 new "nym" properties (in \texttt{dbnary} name space). Additionaly, we defined a class called \texttt{dbnary:LexicalEntity} that is defined as the union of LEMON lexical entries and lexical senses. The "nym" properties domain and range are lexical entities. 

Most of these properties do link a \textit{lexical entry} to a \textit{vocable}, as there is not enough information in wiktionary to promote this relation to a full class \textit{sense to sense} relation. Some of these properties are however promoted to a \textit{Lexical Sense to Vocable} relation when the lexical entry is unambiguous (contains only one sense).
\item[Translations:] As there is no way to represent bilingual translation relation in LEMON, we introduced the \texttt{dbnary:Equivalent} class that collects translation information contained in wiktionary. This class admits several properties:
\begin{itemize}
\item \texttt{dbnary:isTranslationOf} relates the equivalent to its source \textit{lexical entry}. In this extraction process, we decided not to relate the equivalent object to its source \textit{lexical sense}. The reason is that, when some information is available to distinguish between lexical senses, it is mainly targeted to a human audience and there is no simple and reliable process to  link to the correct sense. Instead, we rather keep all the available disambiguation information for a later specialized processing.
\item \texttt{dbnary:targetLanguage} is a data property whose type is a string containing the target language code as defined in ISO639-3 standard.
\item \texttt{dbnary:writtenForm} gives the written form of the translation in the target language. Here, we decided not to relate to a vocable as some translations are not to be defined as lexical entries in the target language.
\item \texttt{dbnary:glose} is a string property that contains any available information used to dentate the lexical sense of the source of the equivalent.
\item \texttt{dbnary:usage} is a string property that contains any available information concerning this equivalent object. It usually gives additional information on the target entry.
\end{itemize}

\end{description}

\subsection{Size of the involved data}

At the time of writing, the extracted data from the most up to date dump files are the following:

\begin{table}[htb]
\begin{minipage}{\linewidth}
\begin{tabular}{lrrrrrr}
\multicolumn{4}{l}{\textbf{Nodes in graphs}}\\
\hline
				 & English &  French  & German & Finnish & Italian & Portuguese \\
Lexical entries &  478764 &  260647\footnote{among which $231522$ words and $24434$ phrases.}  
				 					   & 101867  &  30478 & 24030   & 31105         \\
Vocables 	     & 458317  & 270048  & 166567   & 30946 & 29591  &  32784    \\
Lexical Senses
			     & 386030  & 341720  & 88780   & 38713   &  33731  & 55331      \\
Equivalents
			     & 942425  & 406947 & 438379  & 101733 & 56883   & 49029       \\
%\multicolumn{4}{l}{\textbf{Relations in graphs}}\\
%\hline
%syn	& 65103& 55434& 76606\\
%qsyn\footnote{This relation is only available in French language edition. Other language editions do not distinguish between synonyms and quasi synonyms.}
%	& -& 2666 & -\\
%ant	& 9964& 8760& 34691\\
%holo	& 0  & 5415& 0 \\
%mero	& 224& 4996&0 \\
%hyper	& 1047& 11272& 49051\\
%hypo	& 3144& 17601& 54733\\
\end{tabular}
\end{minipage}
\caption{Size of the extracted lexical networks.}
\label{table:size}
\end{table}

As the extraction is performed each time a wiktionary dump is available, this numbers are constantly evolving, as the wiktionary data is evolving and as the extractor itself maybe improved.

%Stats on RDF file: file:///home/serasset/dev/wiktionary/extracts/lemon/fr/fr_dbnary_lemon_20120906.tut
% lexical entries: 4691 (+231522 words/+ 24434 phrases). Total: 260647
%270048 vocables.
%341720 senses.
%406947 equivalents.
%Stats on RDF file: file:///home/serasset/dev/wiktionary/extracts/lemon/en/en_dbnary_lemon_20120831.tut
% lexical entries: 478764 (+0 words/+ 0 phrases). Total: 478764
%458317 vocables.
%386030 senses.
%942425 equivalents.
%Stats on RDF file: file:///home/serasset/dev/wiktionary/extracts/lemon/de/de_dbnary_lemon_20120909.tut
% lexical entries: 101867 (+0 words/+ 0 phrases). Total: 101867
%166567 vocables.
%88780 senses.
%438379 equivalents.
%Stats on RDF file: file:///home/serasset/dev/wiktionary/extracts/lemon/it/it_dbnary_lemon_20120906.tut
% lexical entries: 24030 (+0 words/+ 0 phrases). Total: 24030
%29591 vocables.
%33731 senses.
%56883 equivalents.
%Stats on RDF file: file:///home/serasset/dev/wiktionary/extracts/lemon/pt/pt_dbnary_lemon_20120905.tut
% lexical entries: 31105 (+0 words/+ 0 phrases). Total: 31105
%32784 vocables.
%55331 senses.
%49029 equivalents.
%Stats on RDF file: file:///home/serasset/dev/wiktionary/extracts/lemon/fi/fi_dbnary_lemon_20120903.tut
% lexical entries: 30478 (+0 words/+ 0 phrases). Total: 30478
%30946 vocables.
%38713 senses.
%101733 equivalents.

% and Portuguese ($397$ Mb)

%-rw-r--r--. 1 serasset geta 608M Oct 13 22:03 dewkt.xml
%-rw-r--r--. 1 serasset geta 3.9G Oct 13 22:02 enwkt.xml
%-rw-r--r--. 1 serasset geta 3.0G Oct 13 21:59 frwkt.xml
%-rw-r--r--. 1 serasset geta 390M Oct 13 22:03 ptwkt.xml

%Stats on RDF file: file:///Users/serasset/dev/wiktionary/extracts/RDF20120305/fr_extract_20120305.tut
%260467 lexical entries.
%246168 lemmas.
%395227 equivalents.
%106151 relations.
%330681 definitions.
%330681 senses.
%1669375 total nodes.
%ant: 8760
%holo: 5415
%hyper: 11272
%hypo: 17601
%mero: 4996
%qsyn: 2666
%syn: 55434
%fra translation in frawiktionary for entry[http://getalp.org/dbnary/fra#__tr_fra_4_crocodile_nain, http://www.lexicalmarkupframework.org/lmf/r14#isPartOf, http://getalp.org/dbnary/fra#crocodile_nain]
%source & eng & fra & deu  & others //
%fra & 73168 & 24 & 31589 & 290190//%394971
%
%
%Stats on RDF file: file:///Users/serasset/dev/wiktionary/extracts/RDF20120305/de_extract_20120305.tut
%155258 lexical entries.
%90207 lemmas.
%417687 equivalents.
%215085 relations.
%80934 definitions.
%80934 senses.
%1040105 total nodes.
%ant: 34691
%hyper: 49051
%hypo: 54733
%syn: 76606
%deu translation in deuwiktionary for entry[http://getalp.org/dbnary/deu#__tr_deu_5_Pantherpilz, http://www.lexicalmarkupframework.org/lmf/r14#isPartOf, http://getalp.org/dbnary/deu#Pantherpilz]
%source & eng & fra & deu  & others //
%deu & 68305 & 57400 & 4 & 291605//%417314
%
%
%Stats on RDF file: file:///Users/serasset/dev/wiktionary/extracts/RDF20120305/en_extract_20120305.tut
%414929 lexical entries.
%402442 lemmas.
%497204 equivalents.
%79487 relations.
%354359 definitions.
%354359 senses.
%2102780 total nodes.
%ant: 9964
%hyper: 1047
%hypo: 3144
%mero: 224
%syn: 65103
%eng translation in engwiktionary for entry[http://getalp.org/dbnary/eng#__tr_eng_1_obsolescence, http://www.lexicalmarkupframework.org/lmf/r14#isPartOf, http://getalp.org/dbnary/eng#obsolescence]
%source & eng & fra & deu  & others //
%eng & 0 & 33290 & 32083 & 430898//%496271


\section{Conclusion and Perspectives}

The current paper shows preliminary results on an open source tool to extract a LEMON based lexical network from different wiktionary language editions. Such a work is interesting for many users that will be able to use the extracted data in their own NLP system. Moreover, as the extracted resource uses the Resource Description Framework (RDF) standard and the LEMON model, the extracted data is also directly usable for researchers on the Semantic Web, where it could be used to ease the ontology alignment systems when terms in different languages are used to describe ontologies of a domain.

Our next objectives are to better generalize the treatments of the current extractors, so that it will be easier to create extractors for other languages. We are currently working on the Russian and we welcome all initiative aiming at the addition of new language to this open-source tool.

\section{Acknowledgements}

The work presented in this paper was conducted in the Videosense project, funded by the French National Research Agency (ANR) under its CONTINT 2009 programme (grant ANR-09-CORD-026).

\bibliographystyle{plainnat}      % basic style, author-year citations
\bibliography{biblio}   % name your BibTeX data base

%\nocite{*}
\end{document}

